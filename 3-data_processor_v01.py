# -*- coding: utf-8 -*-
import pandas as pd
from pathlib import Path
from industry_name_mapping import industry_name_mapping

# === ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ ===
raw_stock_dir = Path("data/raw/japan_all_stock")
raw_index_dir = Path("data/raw/tosho_index")
sector_dir = Path("data/processed_data/sector_summary")
momentum_dir = Path("data/processed_data/momentum_summary")
sector_dir.mkdir(parents=True, exist_ok=True)
momentum_dir.mkdir(parents=True, exist_ok=True)

# === æœ€æ–°CSVå–å¾— ===
stock_files = sorted(raw_stock_dir.glob("japan-all-stock-prices_*.csv"))
index_files = sorted(raw_index_dir.glob("tosho-index-data_*.csv"))
latest_stock = stock_files[-1]
latest_index = index_files[-1]

# æ—¥ä»˜
date_str = latest_stock.stem.split("_")[-1]
date_slash = f"{date_str[:4]}/{date_str[4:6]}/{date_str[6:]}"
print(f"ğŸ“… å¯¾è±¡æ—¥: {date_slash}")

# === CSVèª­è¾¼ ===
stock_df = pd.read_csv(latest_stock, encoding="cp932")
stock_df = stock_df[stock_df["æ¥­ç¨®"] != "æ ªä¾¡æŒ‡æ•°"] # ã€Œæ ªä¾¡æŒ‡æ•°ã€ã‚’é™¤å¤–

index_df = pd.read_csv(latest_index, encoding="cp932")

# æ—¥ä»˜åˆ—çµ±ä¸€
for df in [stock_df, index_df]:
    if "æ—¥ä»˜" in df.columns:
        df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"]).dt.strftime("%Y/%m/%d")

# æ¥­ç¨®åçµ±ä¸€
stock_df["æ¥­ç¨®"] = stock_df["æ¥­ç¨®"].replace(industry_name_mapping)

# æ•°å€¤åŒ–
stock_df["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"] = (
    stock_df["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"].astype(str).str.replace(",", "").replace("-", "0").astype(float)
)
stock_df["å‰æ—¥æ¯”"] = pd.to_numeric(stock_df["å‰æ—¥æ¯”"], errors="coerce").fillna(0)
stock_df["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"] = pd.to_numeric(stock_df["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"], errors="coerce").fillna(0)

# æ™‚ä¾¡ç·é¡å¸¯åˆ†é¡
def classify_market_cap(x):
    if x < 10_000:
        return "å°å‹"
    elif x < 100_000:
        return "ä¸­å‹"
    elif x < 1_000_000:
        return "å¤§å‹"
    else:
        return "è¶…å¤§å‹"
stock_df["æ™‚ä¾¡ç·é¡å¸¯"] = stock_df["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"].apply(classify_market_cap)

# ä¸Šæ˜‡/ä¸‹è½ãƒ•ãƒ©ã‚°
stock_df["ä¸Šæ˜‡ãƒ•ãƒ©ã‚°"] = stock_df["å‰æ—¥æ¯”"] > 0
stock_df["ä¸‹è½ãƒ•ãƒ©ã‚°"] = stock_df["å‰æ—¥æ¯”"] <= 0

# === sector_summary é›†è¨ˆ ===
def aggregate_sector(stock_df, index_df):
    result = []
    grouped = stock_df.groupby(["æ¥­ç¨®", "æ™‚ä¾¡ç·é¡å¸¯"])
    for (industry, cap), group in grouped:
        up = group["ä¸Šæ˜‡ãƒ•ãƒ©ã‚°"].sum()
        down = group["ä¸‹è½ãƒ•ãƒ©ã‚°"].sum()
        total_val = group["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"].sum()
        if cap == "å…¨ä½“":
            weighted_avg = 0  # å¾Œã§å…¨ä½“ã‚’ index_df ã‹ã‚‰å–å¾—
        else:
            weighted_avg = (group["å‰æ—¥æ¯”ï¼ˆï¼…ï¼‰"] * group["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"]).sum() / max(group["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"].sum(),1)
        result.append({
            "æ—¥ä»˜": date_slash,
            "æ¥­ç¨®": industry,
            "æ™‚ä¾¡ç·é¡å¸¯": cap,
            "ä¸Šæ˜‡éŠ˜æŸ„æ•°": int(up),
            "ä¸‹è½éŠ˜æŸ„æ•°": int(down),
            "æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡": round(weighted_avg,3),
            "å£²è²·ä»£é‡‘åˆè¨ˆ": int(total_val)
        })
    sector_df = pd.DataFrame(result)

    # å…¨ä½“è¡Œè¿½åŠ 
    new_rows = []
    for industry, group in sector_df.groupby("æ¥­ç¨®"):
        total_val = group["å£²è²·ä»£é‡‘åˆè¨ˆ"].sum()
        weighted_avg = (group["æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡"] * group["å£²è²·ä»£é‡‘åˆè¨ˆ"]).sum() / max(total_val,1)
        new_rows.append({
            "æ—¥ä»˜": date_slash,
            "æ¥­ç¨®": industry,
            "æ™‚ä¾¡ç·é¡å¸¯": "å…¨ä½“",
            "ä¸Šæ˜‡éŠ˜æŸ„æ•°": int(group["ä¸Šæ˜‡éŠ˜æŸ„æ•°"].sum()),
            "ä¸‹è½éŠ˜æŸ„æ•°": int(group["ä¸‹è½éŠ˜æŸ„æ•°"].sum()),
            "æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡": 0,  # å¾Œã§ index_df ã‹ã‚‰ç½®æ›
            "å£²è²·ä»£é‡‘åˆè¨ˆ": int(total_val)
        })
    sector_df = pd.concat([sector_df, pd.DataFrame(new_rows)], ignore_index=True)

    # å…¨ä½“åŒºåˆ†ã®å¹³å‡é¨°è½ç‡ã‚’ index_df ã‹ã‚‰å–å¾—
    for idx, row in sector_df.iterrows():
        if row["æ™‚ä¾¡ç·é¡å¸¯"] == "å…¨ä½“":
            matched = index_df[index_df["æŒ‡æ•°å"] == row["æ¥­ç¨®"]]
            if not matched.empty:
                sector_df.at[idx, "æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡"] = float(matched.iloc[0]["å‰æ—¥æ¯”ï¼ˆï¼…ï¼‰"])
    return sector_df

sector_df = aggregate_sector(stock_df, index_df)

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå…¨ä½“ï¼‰
ranking = sector_df[sector_df["æ™‚ä¾¡ç·é¡å¸¯"]=="å…¨ä½“"].copy()
ranking["å¹³å‡é¨°è½ç‡é †ä½"] = ranking["æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡"].rank(ascending=False, method="min").astype(int)
sector_df = sector_df.merge(ranking[["æ¥­ç¨®","å¹³å‡é¨°è½ç‡é †ä½"]], on="æ¥­ç¨®", how="left")

# ä¿å­˜
output_file = sector_dir / f"{date_str}_sector_summary.csv"
sector_df.to_csv(output_file, index=False, encoding="utf-8-sig")
print(f"âœ… sector_summary ä¿å­˜: {output_file}")

# === momentum_summary é›†è¨ˆ ===
def compute_momentum(stock_files, date_str):
    stock_files_sorted = sorted(stock_files)
    
    # æœ€æ–°æ—¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    target_idx = [i for i,f in enumerate(stock_files_sorted) if f.stem.endswith(date_str)][0]
    # éå»20å–¶æ¥­æ—¥åˆ†
    start_idx = max(0, target_idx-19)
    recent_files = stock_files_sorted[start_idx:target_idx+1]

    df_list = []
    for f in recent_files:
        df_tmp = pd.read_csv(f, encoding="cp932")

        if "æ¥­ç¨®" in df_tmp.columns:
            df_tmp = df_tmp[df_tmp["æ¥­ç¨®"] != "æ ªä¾¡æŒ‡æ•°"] # ãƒ€ãƒŸãƒ¼è¡Œå‰Šé™¤

        df_tmp["æ¥­ç¨®"] = df_tmp["æ¥­ç¨®"].replace(industry_name_mapping)
        val_col_candidates = [c for c in df_tmp.columns if "å£²è²·ä»£é‡‘" in c]
        if not val_col_candidates:
            continue
        val_col = val_col_candidates[0]
        df_tmp["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"] = pd.to_numeric(df_tmp[val_col].astype(str).str.replace(",", ""), errors="coerce").fillna(0)
        if "æ—¥ä»˜" in df_tmp.columns:
            df_tmp["æ—¥ä»˜"] = pd.to_datetime(df_tmp["æ—¥ä»˜"], format="%Y%m%d")
        df_list.append(df_tmp[["æ—¥ä»˜","æ¥­ç¨®","å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"]])
        # éå»20å–¶æ¥­æ—¥åˆ†ã‚’çµåˆ
        df_concat = pd.concat(df_list, ignore_index=True)
        df_concat = df_concat.sort_values(["æ¥­ç¨®","æ—¥ä»˜"])

    # æ—¥ä»˜ã”ã¨æ¥­ç¨®åˆ¥å£²è²·ä»£é‡‘åˆè¨ˆ
    daily_sum = df_concat.groupby(["æ—¥ä»˜","æ¥­ç¨®"], as_index=False)["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"].sum()

    # å„æ¥­ç¨®ã”ã¨ã® rolling å¹³å‡
    for n in [3,5,10,20]:
        col_name = f"å£²è²·ä»£é‡‘{n}æ—¥å¹³å‡"
        daily_sum[col_name] = daily_sum.groupby("æ¥­ç¨®")["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"].transform(
            lambda x: x.rolling(n, min_periods=1).mean()
        )

    # æ¯”ç‡è¨ˆç®—
    daily_sum["å£²è²·ä»£é‡‘5æ—¥å¹³å‡/20æ—¥å¹³å‡æ¯”ç‡"] = (daily_sum["å£²è²·ä»£é‡‘5æ—¥å¹³å‡"] / daily_sum["å£²è²·ä»£é‡‘20æ—¥å¹³å‡"]).round(3)
    daily_sum["å£²è²·ä»£é‡‘3æ—¥å¹³å‡/10æ—¥å¹³å‡æ¯”ç‡"] = (daily_sum["å£²è²·ä»£é‡‘3æ—¥å¹³å‡"] / daily_sum["å£²è²·ä»£é‡‘10æ—¥å¹³å‡"]).round(3)

    # æœ€æ–°æ—¥ã ã‘æŠ½å‡º
    latest_date = daily_sum["æ—¥ä»˜"].max()
    momentum_df = daily_sum[daily_sum["æ—¥ä»˜"]==latest_date].copy()

    # ä¿å­˜ç”¨ã«æ—¥ä»˜ã‚’ "YYYY/MM/DD" ã«å¤‰æ›
    momentum_df["æ—¥ä»˜"] = momentum_df["æ—¥ä»˜"].dt.strftime("%Y/%m/%d")

    return momentum_df

momentum_df = compute_momentum(stock_files, date_str)

# ä¿å­˜
momentum_file = momentum_dir / f"{date_str}_momentum_summary.csv"
momentum_df.to_csv(momentum_file, index=False, encoding="utf-8-sig")
print(f"âœ… momentum_summary ä¿å­˜: {momentum_file}")