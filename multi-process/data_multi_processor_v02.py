# -*- coding: utf-8 -*-
import pandas as pd
from pathlib import Path
from industry_name_mapping import industry_name_mapping

# === ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ ===
raw_stock_dir = Path("data/raw/japan_all_stock")
raw_index_dir = Path("data/raw/tosho_index")
sector_dir = Path("data/processed_data/sector_summary")
momentum_dir = Path("data/processed_data/momentum_summary")
sector_dir.mkdir(parents=True, exist_ok=True)
momentum_dir.mkdir(parents=True, exist_ok=True)

# === ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾— ===
stock_files = sorted(raw_stock_dir.glob("japan-all-stock-prices_*.csv"))
index_files = sorted(raw_index_dir.glob("tosho-index-data_*.csv"))

# --- å…±é€šé–¢æ•° ---
def classify_market_cap(x):
    if x < 10_000:
        return "å°å‹"
    elif x < 100_000:
        return "ä¸­å‹"
    elif x < 1_000_000:
        return "å¤§å‹"
    else:
        return "è¶…å¤§å‹"

def aggregate_sector(stock_df, index_df, date_str, date_slash):
    result = []
    grouped = stock_df.groupby(["æ¥­ç¨®", "æ™‚ä¾¡ç·é¡å¸¯"])
    for (industry, cap), group in grouped:
        up = group["ä¸Šæ˜‡ãƒ•ãƒ©ã‚°"].sum()
        down = group["ä¸‹è½ãƒ•ãƒ©ã‚°"].sum()
        total_val = group["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"].sum()
        weighted_avg = (group["å‰æ—¥æ¯”ï¼ˆï¼…ï¼‰"] * group["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"]).sum() / max(group["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"].sum(), 1)
        result.append({
            "æ—¥ä»˜": date_slash,
            "æ¥­ç¨®": industry,
            "æ™‚ä¾¡ç·é¡å¸¯": cap,
            "ä¸Šæ˜‡éŠ˜æŸ„æ•°": int(up),
            "ä¸‹è½éŠ˜æŸ„æ•°": int(down),
            "æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡": round(weighted_avg, 3),
            "å£²è²·ä»£é‡‘åˆè¨ˆ": int(total_val)
        })
    sector_df = pd.DataFrame(result)

    # å…¨ä½“è¡Œè¿½åŠ 
    new_rows = []
    for industry, group in sector_df.groupby("æ¥­ç¨®"):
        total_val = group["å£²è²·ä»£é‡‘åˆè¨ˆ"].sum()
        new_rows.append({
            "æ—¥ä»˜": date_slash,
            "æ¥­ç¨®": industry,
            "æ™‚ä¾¡ç·é¡å¸¯": "å…¨ä½“",
            "ä¸Šæ˜‡éŠ˜æŸ„æ•°": int(group["ä¸Šæ˜‡éŠ˜æŸ„æ•°"].sum()),
            "ä¸‹è½éŠ˜æŸ„æ•°": int(group["ä¸‹è½éŠ˜æŸ„æ•°"].sum()),
            "æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡": 0,  # å¾Œã§ index_df ã‹ã‚‰ç½®æ›
            "å£²è²·ä»£é‡‘åˆè¨ˆ": int(total_val)
        })
    sector_df = pd.concat([sector_df, pd.DataFrame(new_rows)], ignore_index=True)

    # å…¨ä½“åŒºåˆ†ã®å¹³å‡é¨°è½ç‡ã‚’ index_df ã‹ã‚‰å–å¾—
    for idx, row in sector_df.iterrows():
        if row["æ™‚ä¾¡ç·é¡å¸¯"] == "å…¨ä½“":
            matched = index_df[index_df["æŒ‡æ•°å"] == row["æ¥­ç¨®"]]
            if not matched.empty:
                sector_df.at[idx, "æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡"] = float(matched.iloc[0]["å‰æ—¥æ¯”ï¼ˆï¼…ï¼‰"])
    return sector_df


def compute_momentum(stock_files, date_str):
    stock_files_sorted = sorted(stock_files)
    target_idx = [i for i, f in enumerate(stock_files_sorted) if f.stem.endswith(date_str)]
    if not target_idx:
        return None
    target_idx = target_idx[0]
    start_idx = max(0, target_idx - 19)
    recent_files = stock_files_sorted[start_idx:target_idx + 1]

    df_list = []
    for f in recent_files:
        df_tmp = pd.read_csv(f, encoding="cp932")
        df_tmp = df_tmp[df_tmp["æ¥­ç¨®"] != "æ ªä¾¡æŒ‡æ•°"]
        df_tmp["æ¥­ç¨®"] = df_tmp["æ¥­ç¨®"].replace(industry_name_mapping)
        
        val_col = [c for c in df_tmp.columns if "å£²è²·ä»£é‡‘" in c][0]
        df_tmp["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"] = pd.to_numeric(df_tmp[val_col].astype(str).str.replace(",", ""), errors="coerce").fillna(0)
        
        if "æ—¥ä»˜" in df_tmp.columns:
            df_tmp["æ—¥ä»˜"] = pd.to_datetime(df_tmp["æ—¥ä»˜"].astype(str).str.strip(), format="%Y%m%d", errors="coerce")
        
        df_tmp = df_tmp.dropna(subset=["æ—¥ä»˜"])
        df_list.append(df_tmp[["æ—¥ä»˜","æ¥­ç¨®","å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"]])
        
    # concatå¾Œã«NaTé™¤å¤–
    df_concat = pd.concat(df_list, ignore_index=True)
    df_concat = df_concat.dropna(subset=["æ—¥ä»˜"]).sort_values(["æ¥­ç¨®","æ—¥ä»˜"])
    daily_sum = df_concat.groupby(["æ—¥ä»˜", "æ¥­ç¨®"], as_index=False)["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"].sum()

    for n in [3, 5, 10, 20]:
        daily_sum[f"å£²è²·ä»£é‡‘{n}æ—¥å¹³å‡"] = daily_sum.groupby("æ¥­ç¨®")["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"].transform(lambda x: x.rolling(n, min_periods=1).mean())

    daily_sum["å£²è²·ä»£é‡‘5æ—¥å¹³å‡/20æ—¥å¹³å‡æ¯”ç‡"] = (daily_sum["å£²è²·ä»£é‡‘5æ—¥å¹³å‡"] / daily_sum["å£²è²·ä»£é‡‘20æ—¥å¹³å‡"]).round(3)
    daily_sum["å£²è²·ä»£é‡‘3æ—¥å¹³å‡/10æ—¥å¹³å‡æ¯”ç‡"] = (daily_sum["å£²è²·ä»£é‡‘3æ—¥å¹³å‡"] / daily_sum["å£²è²·ä»£é‡‘10æ—¥å¹³å‡"]).round(3)

    latest_date = daily_sum["æ—¥ä»˜"].max()
    momentum_df = daily_sum[daily_sum["æ—¥ä»˜"] == latest_date].copy()
    momentum_df["æ—¥ä»˜"] = momentum_df["æ—¥ä»˜"].dt.strftime("%Y/%m/%d")

    return momentum_df


# === å…¨å–¶æ¥­æ—¥åˆ†ãƒ«ãƒ¼ãƒ—å‡¦ç† ===
for stock_file, index_file in zip(stock_files, index_files):
    date_str = stock_file.stem.split("_")[-1]
    date_slash = f"{date_str[:4]}/{date_str[4:6]}/{date_str[6:]}"
    output_sector = sector_dir / f"{date_str}_sector_summary.csv"
    output_momentum = momentum_dir / f"{date_str}_momentum_summary.csv"

    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒƒãƒ—
    if output_sector.exists() and output_momentum.exists():
        print(f"â© {date_str} ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã€ã‚¹ã‚­ãƒƒãƒ—")
        continue

    print(f"\nğŸ“… å‡¦ç†é–‹å§‹: {date_slash}")

    # === CSVèª­è¾¼ ===
    stock_df = pd.read_csv(stock_file, encoding="cp932")
    stock_df = stock_df[stock_df["æ¥­ç¨®"] != "æ ªä¾¡æŒ‡æ•°"]
    index_df = pd.read_csv(index_file, encoding="cp932")

    for df in [stock_df, index_df]:
        if "æ—¥ä»˜" in df.columns:
            df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"]).dt.strftime("%Y/%m/%d")

    stock_df["æ¥­ç¨®"] = stock_df["æ¥­ç¨®"].replace(industry_name_mapping)
    stock_df["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"] = stock_df["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"].astype(str).str.replace(",", "").replace("-", "0").astype(float)
    stock_df["å‰æ—¥æ¯”"] = pd.to_numeric(stock_df["å‰æ—¥æ¯”"], errors="coerce").fillna(0)
    stock_df["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"] = pd.to_numeric(stock_df["å£²è²·ä»£é‡‘ï¼ˆåƒå††ï¼‰"], errors="coerce").fillna(0)
    stock_df["æ™‚ä¾¡ç·é¡å¸¯"] = stock_df["æ™‚ä¾¡ç·é¡ï¼ˆç™¾ä¸‡å††ï¼‰"].apply(classify_market_cap)
    stock_df["ä¸Šæ˜‡ãƒ•ãƒ©ã‚°"] = stock_df["å‰æ—¥æ¯”"] > 0
    stock_df["ä¸‹è½ãƒ•ãƒ©ã‚°"] = stock_df["å‰æ—¥æ¯”"] <= 0

    # === sector_summary ===
    sector_df = aggregate_sector(stock_df, index_df, date_str, date_slash)
    ranking = sector_df[sector_df["æ™‚ä¾¡ç·é¡å¸¯"] == "å…¨ä½“"].copy()
    ranking["å¹³å‡é¨°è½ç‡é †ä½"] = ranking["æ™‚ä¾¡ç·é¡åŠ é‡å¹³å‡é¨°è½ç‡"].rank(ascending=False, method="min").astype(int)
    sector_df = sector_df.merge(ranking[["æ¥­ç¨®", "å¹³å‡é¨°è½ç‡é †ä½"]], on="æ¥­ç¨®", how="left")
    sector_df.to_csv(output_sector, index=False, encoding="utf-8-sig")
    print(f"âœ… sector_summary ä¿å­˜: {output_sector.name}")

    # === momentum_summary ===
    momentum_df = compute_momentum(stock_files, date_str)
    if momentum_df is not None:
        momentum_df.to_csv(output_momentum, index=False, encoding="utf-8-sig")
        print(f"âœ… momentum_summary ä¿å­˜: {output_momentum.name}")

print("\nğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†ï¼")