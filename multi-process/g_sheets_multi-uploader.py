# g_sheets_multi_uploader.pyï¼ˆç¯„å›²æŒ‡å®šç‰ˆï¼‰
import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
import glob
import os
import re
from datetime import datetime

# ------------------------------
# â‘  Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆèªè¨¼
# ------------------------------
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
SERVICE_ACCOUNT_FILE = "credentials.json"
creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
gc = gspread.authorize(creds)

# ------------------------------
# â‘¡ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š
# ------------------------------
SPREADSHEET_ID = "1CTRQdjsgFsRPgRdsT_c_rJheztivNAa1gyTKjxL-QR4"
sh = gc.open_by_key(SPREADSHEET_ID)
log_sheet = sh.worksheet("sector_momentum_log")

# ------------------------------
# â‘¢ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡CSVã‚’å–å¾—
# ------------------------------
processed_dir = os.path.join("data", "processed")
csv_files = sorted(glob.glob(os.path.join(processed_dir, "sector_summary_*.csv")))
if not csv_files:
    raise FileNotFoundError("âŒ Processed CSV ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ------------------------------
# â‘£ æ—¥ä»˜ç¯„å›²æŒ‡å®š
# ------------------------------
# YYYY-MM-DDå½¢å¼ã§æŒ‡å®š
start_date = datetime.strptime("2025-09-25", "%Y-%m-%d").date()
end_date = datetime.strptime("2025-10-10", "%Y-%m-%d").date()

# CSVãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜æŠ½å‡ºï¼†ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿
def extract_date_from_filename(path):
    m = re.search(r"sector_summary_(\d{8})\.csv", path)
    if m:
        return datetime.strptime(m.group(1), "%Y%m%d").date()
    return None

csv_files_to_upload = [
    f for f in csv_files
    if extract_date_from_filename(f) and start_date <= extract_date_from_filename(f) <= end_date
]

if not csv_files_to_upload:
    print("âš ï¸ æŒ‡å®šç¯„å›²å†…ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    exit()

print(f"ğŸ“¦ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡CSVæ•°: {len(csv_files_to_upload)} ä»¶")

# ------------------------------
# â‘¤ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
# ------------------------------
existing_data = log_sheet.get_all_values()
existing_body = existing_data[1:] if len(existing_data) > 1 else []
existing_dates = [row[0] for row in existing_body] if existing_body else []

# ------------------------------
# â‘¥ CSVã‚’é †æ¬¡ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ------------------------------
for csv_file in csv_files_to_upload:
    df = pd.read_csv(csv_file)
    csv_date = str(df["æ—¥ä»˜"].iloc[0])

    if csv_date in existing_dates:
        print(f"âš ï¸ {csv_date} ã®ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«å­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        continue

    log_values = df.values.tolist()
    log_sheet.insert_rows(log_values, row=2)
    print(f"âœ… {csv_date} ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ ({len(log_values)} è¡Œ)")

print("ğŸ‰ æŒ‡å®šç¯„å›²åˆ†ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")